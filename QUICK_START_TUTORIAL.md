# Quick Start Tutorial

## üöÄ Privacy-Preserving Agent Finetuner - Get Started in Minutes

This tutorial will get you up and running with privacy-preserving machine learning in just a few steps, showcasing the power of differential privacy, security monitoring, intelligent scaling, and global compliance features.

## üìã Table of Contents

- [Installation](#installation)
- [Basic Privacy-Preserving Training](#basic-privacy-preserving-training)
- [Advanced Features Tutorial](#advanced-features-tutorial)
- [Generation 1: Research Capabilities](#generation-1-research-capabilities)
- [Generation 2: Security & Resilience](#generation-2-security--resilience)
- [Generation 3: Scaling & Performance](#generation-3-scaling--performance)
- [Global Deployment Features](#global-deployment-features)
- [Real-World Use Cases](#real-world-use-cases)
- [Next Steps](#next-steps)

---

## ‚öôÔ∏è Installation

### Prerequisites

Ensure you have the following installed:
- **Python 3.9+** (3.11 recommended)
- **CUDA 11.8+** (for GPU support)
- **Git** for cloning the repository

### Quick Installation

```bash
# Clone the repository
git clone https://github.com/your-org/privacy-preserving-agent-finetuner
cd privacy-preserving-agent-finetuner

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Alternative: Install with Poetry (recommended)
pip install poetry
poetry install
poetry shell

# Verify installation
python -c "from privacy_finetuner import PrivateTrainer; print('‚úÖ Installation successful!')"
```

### Docker Installation (Recommended for Production)

```bash
# Pull the latest image
docker pull privacy-ml/framework:latest

# Run with basic setup
docker run -it --gpus all -p 8080:8080 privacy-ml/framework:latest

# Run with volume mapping for models and data
docker run -it --gpus all \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/data:/app/data \
  -p 8080:8080 \
  privacy-ml/framework:latest
```

---

## üîß Basic Privacy-Preserving Training

Let's start with a simple example that demonstrates the core privacy-preserving capabilities.

### Step 1: Create Your First Privacy-Preserving Model

```python
#!/usr/bin/env python3
"""
Quick Start Tutorial: Basic Privacy-Preserving Training
"""

from privacy_finetuner import PrivateTrainer, PrivacyConfig
import json

# Step 1: Configure Privacy Parameters
privacy_config = PrivacyConfig(
    epsilon=1.0,        # Privacy budget (lower = more private)
    delta=1e-5,         # Privacy parameter (typically 1e-5)
    max_grad_norm=1.0,  # Gradient clipping threshold
    noise_multiplier=0.5  # Noise scale (auto-calculated if None)
)

# Step 2: Initialize the Privacy-Preserving Trainer
trainer = PrivateTrainer(
    model_name="microsoft/DialoGPT-small",  # Start with a small model
    privacy_config=privacy_config,
    use_mcp_gateway=True,  # Enable context protection
    device="auto"  # Automatically select GPU/CPU
)

print("‚úÖ Privacy-preserving trainer initialized!")
print(f"üìä Privacy Budget: Œµ={privacy_config.epsilon}, Œ¥={privacy_config.delta}")

# Step 3: Create Sample Training Data
sample_data = [
    {
        "input": "How can I improve customer satisfaction?",
        "output": "Focus on response time, product quality, and personalized service."
    },
    {
        "input": "What are the benefits of renewable energy?",
        "output": "Renewable energy reduces costs, environmental impact, and dependency on fossil fuels."
    },
    {
        "input": "How do I write effective marketing copy?",
        "output": "Use clear messaging, focus on benefits, include social proof, and end with a strong call-to-action."
    },
    # Add more examples here...
]

# Save sample data to file
with open('sample_training_data.jsonl', 'w') as f:
    for item in sample_data:
        f.write(json.dumps(item) + '\n')

# Step 4: Train with Privacy Guarantees
print("\nüîÑ Starting privacy-preserving training...")

result = trainer.train(
    dataset="sample_training_data.jsonl",
    epochs=2,               # Start with fewer epochs for testing
    batch_size=4,           # Smaller batch size for demonstration
    learning_rate=5e-5,
    output_dir="./privacy_models/quick_start",
    save_steps=50,
    eval_steps=25
)

print("\nüéâ Training completed successfully!")
print(f"üìà Final Training Loss: {result.training_history.loss[-1]:.4f}")
print(f"üîí Privacy Spent: Œµ={result.privacy_spent.epsilon:.6f}")

# Step 5: Generate Privacy Report
privacy_report = trainer.get_privacy_report()

print(f"\nüìã Privacy Report Summary:")
print(f"  Privacy Budget Used: {privacy_report.privacy_spent.epsilon:.6f}")
print(f"  Privacy Remaining: {privacy_report.privacy_remaining.epsilon:.6f}")
print(f"  Training Rounds: {privacy_report.training_rounds}")
print(f"  Theoretical Guarantee: Œµ‚â§{privacy_report.theoretical_guarantees.epsilon_theoretical:.6f}")

# Step 6: Test the Model
print(f"\nüß™ Testing the privacy-preserved model:")

# Load the trained model
trainer.load_model("./privacy_models/quick_start")

# Test inference (with privacy protection)
test_input = "What are some best practices for data security?"
response = trainer.generate(
    test_input, 
    max_length=100, 
    privacy_safe=True  # Apply privacy protection during inference
)

print(f"Input: {test_input}")
print(f"Response: {response}")
```

### Expected Output

```
‚úÖ Privacy-preserving trainer initialized!
üìä Privacy Budget: Œµ=1.0, Œ¥=1e-05

üîÑ Starting privacy-preserving training...
[Privacy] Applying DP-SGD with noise multiplier: 0.5
[Training] Epoch 1/2, Step 1/4: Loss=2.8431, Privacy spent: Œµ=0.2341
[Training] Epoch 1/2, Step 2/4: Loss=2.6829, Privacy spent: Œµ=0.4682
[Training] Epoch 1/2, Step 3/4: Loss=2.5247, Privacy spent: Œµ=0.7023
[Training] Epoch 1/2, Step 4/4: Loss=2.3896, Privacy spent: Œµ=0.9364
[Training] Epoch 2/2: Completed with final privacy budget: Œµ=1.0000

üéâ Training completed successfully!
üìà Final Training Loss: 2.1534
üîí Privacy Spent: Œµ=1.000000

üìã Privacy Report Summary:
  Privacy Budget Used: 1.000000
  Privacy Remaining: 0.000000
  Training Rounds: 8
  Theoretical Guarantee: Œµ‚â§1.024531

üß™ Testing the privacy-preserved model:
Input: What are some best practices for data security?
Response: Implement strong authentication, encrypt sensitive data, maintain regular backups, and conduct security audits.
```

---

## üéØ Advanced Features Tutorial

Now let's explore the advanced capabilities across all generations of the framework.

### Context Protection with Sensitive Data

```python
#!/usr/bin/env python3
"""
Advanced Tutorial: Context Protection and Security
"""

from privacy_finetuner import ContextGuard, RedactionStrategy
from privacy_finetuner.security import ThreatDetector
import time

# Initialize Context Protection
print("üõ°Ô∏è Setting up Advanced Context Protection...")

context_guard = ContextGuard(
    strategies=[
        RedactionStrategy.PII_REMOVAL,      # Remove personally identifiable information
        RedactionStrategy.ENTITY_HASHING,   # Hash entities while preserving relationships
        RedactionStrategy.SEMANTIC_ENCRYPTION # Encrypt meaning while preserving structure
    ],
    sensitivity_threshold=0.8,
    preserve_structure=True
)

# Test with sensitive data
sensitive_texts = [
    "John Smith (SSN: 123-45-6789) from john.smith@company.com needs access to medical records.",
    "Credit card 4532-1234-5678-9012 was used for $1,500 payment by Sarah Johnson.",
    "Employee ID E12345 accessed confidential files from IP 192.168.1.100 at 14:30.",
]

print("\nüîç Applying Context Protection:")
for i, text in enumerate(sensitive_texts, 1):
    print(f"\n--- Example {i} ---")
    print(f"Original: {text}")
    
    # Apply protection
    protection_result = context_guard.protect(
        text, 
        sensitivity_level="high",
        preserve_entities=["organization", "time"]
    )
    
    print(f"Protected: {protection_result.protected_text}")
    print(f"Sensitivity Score: {protection_result.sensitivity_score:.2f}")
    print(f"Entities Found: {', '.join(protection_result.entities_found)}")

# Batch protection for efficiency
print(f"\n‚ö° Batch Protection (more efficient for multiple texts):")
batch_results = context_guard.batch_protect(sensitive_texts)
for i, result in enumerate(batch_results, 1):
    print(f"{i}. {result.protected_text}")
```

### Real-Time Security Monitoring

```python
#!/usr/bin/env python3
"""
Advanced Tutorial: Real-Time Security Monitoring
"""

from privacy_finetuner.security import ThreatDetector, ThreatType
import time
import random

# Initialize Threat Detection System
print("üö® Setting up Real-Time Security Monitoring...")

threat_detector = ThreatDetector(
    alert_threshold=0.7,
    monitoring_interval=0.5,
    enable_automated_response=True
)

# Start monitoring
threat_detector.start_monitoring()

# Register custom alert handler
def custom_alert_handler(alert):
    print(f"üö® SECURITY ALERT: {alert.threat_type.value}")
    print(f"   Severity: {alert.threat_level.value}")
    print(f"   Description: {alert.description}")
    print(f"   Recommendations: {', '.join(alert.recommended_actions)}")

threat_detector.register_alert_handler(ThreatType.PRIVACY_BUDGET_EXHAUSTION, custom_alert_handler)
threat_detector.register_alert_handler(ThreatType.DATA_POISONING, custom_alert_handler)

# Simulate various training scenarios
print("\nüîÑ Simulating training scenarios with security monitoring...")

scenarios = [
    {
        "name": "Normal Training",
        "metrics": {
            "privacy_epsilon_used": 0.3,
            "privacy_epsilon_total": 2.0,
            "gradient_l2_norm": 1.2,
            "current_loss": 1.8,
            "accuracy": 0.85
        }
    },
    {
        "name": "Suspicious High Gradients",
        "metrics": {
            "privacy_epsilon_used": 0.8,
            "privacy_epsilon_total": 2.0,
            "gradient_l2_norm": 15.2,  # Abnormally high
            "current_loss": 4.8,
            "accuracy": 0.45
        }
    },
    {
        "name": "Privacy Budget Near Exhaustion",
        "metrics": {
            "privacy_epsilon_used": 1.95,  # Very close to limit
            "privacy_epsilon_total": 2.0,
            "gradient_l2_norm": 1.1,
            "current_loss": 1.2,
            "accuracy": 0.88
        }
    }
]

for scenario in scenarios:
    print(f"\n--- Scenario: {scenario['name']} ---")
    
    # Detect threats
    alerts = threat_detector.detect_threat(
        training_metrics=scenario["metrics"],
        context={"expected_accuracy": 0.8}
    )
    
    if alerts:
        print(f"‚ö†Ô∏è {len(alerts)} threats detected!")
    else:
        print("‚úÖ No threats detected - training is secure")
    
    time.sleep(1)  # Pause between scenarios

# Stop monitoring
threat_detector.stop_monitoring()

# Get security summary
security_summary = threat_detector.get_security_summary()
print(f"\nüìä Security Summary:")
print(f"  Total Threats Detected: {security_summary['security_metrics']['total_threats_detected']}")
print(f"  Critical Alerts: {security_summary['critical_alerts']}")
print(f"  Monitoring Status: {security_summary['monitoring_status']}")
```

---

## üî¨ Generation 1: Research Capabilities

Explore advanced privacy-preserving algorithms and benchmarking.

### Novel Privacy Algorithms

```python
#!/usr/bin/env python3
"""
Generation 1 Tutorial: Advanced Privacy Algorithms
"""

from privacy_finetuner.research import NovelAlgorithms, BenchmarkSuite
import torch
import numpy as np

# Initialize Research Capabilities
print("üî¨ Initializing Advanced Privacy Research Tools...")

algorithms = NovelAlgorithms(
    algorithm_type="adaptive_dp",
    optimization_target="privacy_utility_tradeoff"
)

benchmark_suite = BenchmarkSuite(
    benchmark_types=["privacy_utility", "performance", "robustness"],
    evaluation_metrics=["accuracy", "privacy_leakage", "training_time"]
)

# Demonstrate Adaptive Privacy Budget Allocation
print("\nüí° Adaptive Privacy Budget Allocation")

# Simulate data with varying sensitivity levels
data_batches = [
    {"batch_id": 1, "sensitivity_score": 0.2, "size": 100},  # Low sensitivity
    {"batch_id": 2, "sensitivity_score": 0.8, "size": 100},  # High sensitivity
    {"batch_id": 3, "sensitivity_score": 0.5, "size": 100},  # Medium sensitivity
    {"batch_id": 4, "sensitivity_score": 0.9, "size": 100},  # Very high sensitivity
    {"batch_id": 5, "sensitivity_score": 0.3, "size": 100},  # Low-medium sensitivity
]

sensitivity_scores = [batch["sensitivity_score"] for batch in data_batches]

# Allocate budget adaptively
total_epsilon = 2.0
adaptive_epsilons = algorithms.adaptive_privacy_budget_allocation(
    data_sensitivity_scores=sensitivity_scores,
    total_epsilon=total_epsilon,
    allocation_strategy="sensitivity_aware"
)

print(f"Total Privacy Budget: Œµ={total_epsilon}")
print("Adaptive Budget Allocation:")
for batch, epsilon in zip(data_batches, adaptive_epsilons):
    print(f"  Batch {batch['batch_id']} (sensitivity: {batch['sensitivity_score']:.1f}): Œµ={epsilon:.4f}")

# Demonstrate Hybrid Privacy Mechanism
print(f"\nüî¨ Hybrid Privacy Mechanisms")

# Create sample data tensor
sample_data = torch.randn(100, 50)  # 100 samples, 50 features

# Apply hybrid privacy protection
hybrid_result = algorithms.hybrid_privacy_mechanism(
    data=sample_data,
    privacy_techniques=["dp", "k_anonymity", "homomorphic"],
    technique_weights=[0.5, 0.3, 0.2]  # DP=50%, K-anonymity=30%, Homomorphic=20%
)

print(f"Original data shape: {sample_data.shape}")
print(f"Protected data shape: {hybrid_result.protected_data.shape}")
print(f"Privacy techniques applied: {', '.join(hybrid_result.techniques_used)}")
print(f"Combined privacy guarantee: Œµ‚â§{hybrid_result.total_epsilon:.4f}")
```

### Privacy-Utility Benchmarking

```python
#!/usr/bin/env python3
"""
Generation 1 Tutorial: Privacy-Utility Benchmarking
"""

from privacy_finetuner.research import BenchmarkSuite
import matplotlib.pyplot as plt
import numpy as np

# Initialize benchmarking suite
benchmark_suite = BenchmarkSuite()

# Simulate benchmark results for different privacy budgets
privacy_budgets = [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]
accuracy_results = []

print("üìä Running Privacy-Utility Tradeoff Analysis...")

for epsilon in privacy_budgets:
    # Simulate training with different privacy budgets
    # (In practice, this would involve actual model training)
    
    # Simulate accuracy degradation with stronger privacy
    base_accuracy = 0.92
    privacy_degradation = np.exp(-epsilon) * 0.15  # More privacy = more degradation
    simulated_accuracy = base_accuracy - privacy_degradation + np.random.normal(0, 0.01)
    
    accuracy_results.append(max(0.5, min(1.0, simulated_accuracy)))  # Clamp to realistic range
    
    print(f"  Œµ={epsilon:4.1f}: Accuracy = {accuracy_results[-1]:.3f}")

# Create Pareto frontier plot
plt.figure(figsize=(10, 6))
plt.plot(privacy_budgets, accuracy_results, 'bo-', linewidth=2, markersize=8)
plt.xlabel('Privacy Budget (Œµ)', fontsize=12)
plt.ylabel('Model Accuracy', fontsize=12)
plt.title('Privacy-Utility Tradeoff Analysis', fontsize=14)
plt.grid(True, alpha=0.3)
plt.axvline(x=1.0, color='r', linestyle='--', alpha=0.7, label='Recommended Œµ=1.0')
plt.legend()
plt.tight_layout()
plt.savefig('privacy_utility_tradeoff.png', dpi=300, bbox_inches='tight')
plt.show()

print(f"\nüìà Privacy-Utility Analysis Complete!")
print(f"  Best accuracy with strong privacy (Œµ=0.1): {accuracy_results[0]:.3f}")
print(f"  Recommended configuration (Œµ=1.0): {accuracy_results[2]:.3f}")
print(f"  Maximum accuracy with weak privacy (Œµ=10.0): {accuracy_results[-1]:.3f}")
```

---

## üõ°Ô∏è Generation 2: Security & Resilience

Explore enterprise-grade security monitoring and failure recovery.

### Comprehensive Failure Recovery

```python
#!/usr/bin/env python3
"""
Generation 2 Tutorial: Failure Recovery System
"""

from privacy_finetuner.resilience import FailureRecoverySystem, FailureType
from privacy_finetuner import PrivateTrainer, PrivacyConfig
import time

# Initialize Recovery System
print("üõ†Ô∏è Setting up Comprehensive Failure Recovery System...")

recovery_system = FailureRecoverySystem(
    checkpoint_dir="tutorial_recovery_checkpoints",
    max_recovery_attempts=3,
    auto_recovery_enabled=True,
    privacy_threshold=0.8
)

# Create some training progress to demonstrate recovery
print("\nüíæ Creating recovery checkpoints...")

# Simulate training progress
training_states = [
    {
        "epoch": 1, "step": 100, "epsilon_spent": 0.2, 
        "loss": 2.5, "accuracy": 0.65, "model_state": "mock_state_1"
    },
    {
        "epoch": 2, "step": 200, "epsilon_spent": 0.5, 
        "loss": 1.8, "accuracy": 0.75, "model_state": "mock_state_2"
    },
    {
        "epoch": 3, "step": 300, "epsilon_spent": 0.8, 
        "loss": 1.2, "accuracy": 0.85, "model_state": "mock_state_3"
    }
]

recovery_points = []
for state in training_states:
    recovery_id = recovery_system.create_recovery_point(
        epoch=state["epoch"],
        step=state["step"],
        model_state={"weights": state["model_state"]},
        optimizer_state={"lr": 5e-5, "momentum": 0.9},
        privacy_state={
            "epsilon_spent": state["epsilon_spent"],
            "epsilon_total": 2.0,
            "delta": 1e-5
        },
        training_metrics={
            "loss": state["loss"],
            "accuracy": state["accuracy"]
        }
    )
    recovery_points.append(recovery_id)
    print(f"‚úÖ Recovery point {recovery_id} created for epoch {state['epoch']}")

# Demonstrate different failure scenarios
failure_scenarios = [
    {
        "name": "GPU Memory Error",
        "type": FailureType.GPU_MEMORY_ERROR,
        "description": "Out of GPU memory during batch processing",
        "components": ["gpu", "trainer"]
    },
    {
        "name": "Privacy Violation",
        "type": FailureType.PRIVACY_VIOLATION,
        "description": "Privacy budget exceeded safe threshold",
        "components": ["privacy_engine", "trainer"]
    },
    {
        "name": "Network Failure", 
        "type": FailureType.NETWORK_FAILURE,
        "description": "Network connectivity lost in distributed training",
        "components": ["distributed_trainer", "communication"]
    }
]

print(f"\nüö® Testing Failure Recovery Scenarios...")

for scenario in failure_scenarios:
    print(f"\n--- Testing: {scenario['name']} ---")
    
    # Simulate failure
    recovery_success = recovery_system.handle_failure(
        failure_type=scenario["type"],
        description=scenario["description"],
        affected_components=scenario["components"]
    )
    
    if recovery_success:
        print(f"‚úÖ Successfully recovered from {scenario['name']}")
    else:
        print(f"‚ùå Failed to recover from {scenario['name']}")
    
    time.sleep(0.5)  # Brief pause

# Get recovery statistics
stats = recovery_system.get_recovery_statistics()
print(f"\nüìà Recovery System Performance:")
print(f"  Total Failures Handled: {stats['total_failures']}")
print(f"  Successful Recoveries: {stats['successful_recoveries']}")
print(f"  Recovery Success Rate: {stats['recovery_rate']:.1%}")
print(f"  Available Recovery Points: {stats['recovery_points_available']}")

# Test system health
print(f"\nüîß Running Recovery System Health Check...")
health_results = recovery_system.test_recovery_system()
print(f"Health Check Results: {len(health_results['recovery_tests'])} tests completed")
for test_name, result in health_results['recovery_tests'].items():
    status = "‚úÖ PASS" if result['passed'] else "‚ùå FAIL"
    print(f"  {test_name}: {status}")
```

---

## ‚ö° Generation 3: Scaling & Performance

Explore intelligent performance optimization and auto-scaling capabilities.

### Performance Optimization

```python
#!/usr/bin/env python3
"""
Generation 3 Tutorial: Performance Optimization
"""

from privacy_finetuner.scaling import PerformanceOptimizer, OptimizationProfile, OptimizationType
import time

# Initialize Performance Optimizer
print("‚ö° Setting up Intelligent Performance Optimization...")

optimizer = PerformanceOptimizer(
    target_throughput=1000.0,
    max_memory_gb=32.0,
    optimization_interval=10.0,
    auto_optimization=True
)

# Create comprehensive optimization profile
optimization_profile = OptimizationProfile(
    profile_name="tutorial_optimization",
    optimization_types=[
        OptimizationType.MEMORY_OPTIMIZATION,
        OptimizationType.COMPUTE_OPTIMIZATION,
        OptimizationType.BATCH_SIZE_OPTIMIZATION,
        OptimizationType.PRIVACY_BUDGET_OPTIMIZATION
    ],
    target_metrics={
        "throughput": 1000.0,
        "memory_efficiency": 0.8,
        "gpu_utilization": 85.0
    },
    resource_constraints={
        "max_memory_gb": 32.0,
        "max_cpu_percent": 90.0
    },
    privacy_constraints={
        "min_privacy_efficiency": 0.75
    }
)

# Set optimization profile
optimizer.set_optimization_profile(optimization_profile)

# Register metrics callback to simulate dynamic conditions
def tutorial_metrics_callback():
    """Simulate varying performance conditions."""
    import random
    return {
        "throughput_samples_per_sec": 800 + random.uniform(-100, 100),
        "memory_utilization_percent": 70 + random.uniform(-15, 15),
        "gpu_utilization_percent": 60 + random.uniform(-20, 20)
    }

optimizer.register_metrics_callback("tutorial_simulation", tutorial_metrics_callback)

# Start optimization
optimizer.start_optimization()
print("‚úÖ Performance optimization started!")

# Monitor optimization for several cycles
print(f"\nüîÑ Monitoring optimization cycles...")

for cycle in range(5):
    print(f"\n--- Optimization Cycle {cycle + 1} ---")
    time.sleep(5)  # Wait for optimization cycle
    
    # Get current optimization status
    summary = optimizer.get_optimization_summary()
    
    print(f"  Active Optimizations: {summary['active_optimizations']}")
    print(f"  Average Throughput: {summary['average_throughput']:.1f} samples/sec")
    print(f"  Target Achievement: {summary['throughput_achievement']:.1f}%")
    print(f"  Total Optimizations Applied: {summary['total_optimizations_applied']}")

# Stop optimization
optimizer.stop_optimization()

# Run performance benchmark
print(f"\nüî¨ Running Performance Benchmark...")
benchmark_results = optimizer.benchmark_optimization_impact(duration_seconds=15)

print(f"üìä Benchmark Results:")
print(f"  Throughput Improvement: {benchmark_results['improvement_summary']['throughput_improvement_percent']:.1f}%")
print(f"  Memory Efficiency Gain: {benchmark_results['improvement_summary']['memory_reduction_percent']:.1f}%")
print(f"  GPU Utilization Boost: {benchmark_results['improvement_summary']['gpu_utilization_improvement']:.1f}%")
print(f"  Optimizations Applied: {len(benchmark_results['optimizations_applied'])}")
```

### Auto-Scaling Demonstration

```python
#!/usr/bin/env python3
"""
Generation 3 Tutorial: Auto-Scaling
"""

from privacy_finetuner.scaling import AutoScaler, ScalingPolicy, ScalingTrigger, NodeType, ScalingDirection
import time

# Initialize Auto-Scaler
print("üìà Setting up Privacy-Aware Auto-Scaling...")

# Create advanced scaling policy
scaling_policy = ScalingPolicy(
    policy_name="tutorial_scaling",
    triggers=[
        ScalingTrigger.GPU_UTILIZATION,
        ScalingTrigger.THROUGHPUT_TARGET,
        ScalingTrigger.PRIVACY_BUDGET_RATE
    ],
    scale_up_threshold={
        "gpu_utilization": 75.0,
        "throughput_target_ratio": 0.6
    },
    scale_down_threshold={
        "gpu_utilization": 25.0,
        "throughput_target_ratio": 1.5
    },
    min_nodes=1,
    max_nodes=5,
    cooldown_period_seconds=10,  # Short cooldown for tutorial
    privacy_constraints={"min_nodes_for_privacy": 2}
)

auto_scaler = AutoScaler(
    scaling_policy=scaling_policy,
    monitoring_interval=5.0,
    enable_cost_optimization=True,
    enable_privacy_preservation=True
)

# Register scaling event callback
def scaling_event_handler(event):
    print(f"üîÑ Scaling Event: {event.scaling_direction.value}")
    print(f"   Reason: {event.reason}")
    print(f"   Nodes Affected: {event.nodes_affected}")
    print(f"   Cost Impact: ${event.cost_impact:.2f}/hr")

auto_scaler.register_scaling_callback("tutorial_handler", scaling_event_handler)

# Initialize with baseline resources
auto_scaler.manual_scale(ScalingDirection.SCALE_OUT, NodeType.GPU_WORKER, 1)
print("‚úÖ Auto-scaler initialized with 1 GPU worker node")

# Start auto-scaling
auto_scaler.start_auto_scaling()

# Simulate load scenarios
load_scenarios = [
    {"name": "Low Load", "gpu_util": 30, "throughput": 1200, "duration": 10},
    {"name": "High Load", "gpu_util": 85, "throughput": 400, "duration": 15},
    {"name": "Normal Load", "gpu_util": 60, "throughput": 800, "duration": 10}
]

print(f"\nüé≠ Simulating Different Load Scenarios...")

for scenario in load_scenarios:
    print(f"\n--- Scenario: {scenario['name']} ---")
    
    # Register scenario-specific metrics
    def scenario_metrics():
        return {
            "gpu_utilization": scenario["gpu_util"],
            "throughput_samples_per_sec": scenario["throughput"],
            "target_throughput": 1000
        }
    
    auto_scaler.register_metrics_collector("scenario_sim", scenario_metrics)
    
    # Wait for scenario duration
    for second in range(scenario["duration"]):
        time.sleep(1)
        if second % 5 == 0:  # Status update every 5 seconds
            status = auto_scaler.get_scaling_status()
            print(f"  [{second}s] Nodes: {status['current_nodes']}, "
                  f"Cost: ${status['current_hourly_cost']:.2f}/hr")

# Stop auto-scaling
auto_scaler.stop_auto_scaling()

# Generate cost analysis
cost_analysis = auto_scaler.optimize_cost()
print(f"\nüí∞ Cost Analysis Results:")
print(f"  Current Hourly Cost: ${cost_analysis['current_hourly_cost']:.2f}")
print(f"  Daily Projected Cost: ${cost_analysis['daily_projected_cost']:.2f}")
print(f"  Monthly Projected Cost: ${cost_analysis['monthly_projected_cost']:.2f}")

if cost_analysis['optimization_recommendations']:
    print(f"  Cost Optimization Recommendations:")
    for rec in cost_analysis['optimization_recommendations'][:3]:  # Show top 3
        print(f"    ‚Ä¢ {rec['action']}: {rec['description']}")
        print(f"      Potential Savings: ${rec['potential_savings']:.2f}/hr")
```

---

## üåç Global Deployment Features

Explore internationalization and compliance management capabilities.

### Multi-Language Support

```python
#!/usr/bin/env python3
"""
Global-First Tutorial: Internationalization
"""

from privacy_finetuner.global_first import I18nManager, SupportedLocale
import time

# Initialize Internationalization Manager
print("üåê Setting up Global Internationalization Support...")

i18n = I18nManager(
    default_locale=SupportedLocale.EN_US,
    fallback_locale=SupportedLocale.EN_US,
    enable_auto_detection=True
)

# Demonstrate multi-language support
supported_locales = [
    SupportedLocale.EN_US,   # English (US)
    SupportedLocale.DE_DE,   # German (Germany)
    SupportedLocale.FR_FR,   # French (France)
    SupportedLocale.JA_JP,   # Japanese (Japan)
    SupportedLocale.AR_SA,   # Arabic (Saudi Arabia)
    SupportedLocale.ZH_CN    # Chinese (China)
]

translation_examples = [
    "app.title",
    "privacy.consent",
    "training.started",
    "error.insufficient_budget",
    "button.save"
]

print(f"\nüî§ Multi-Language Translation Examples:")
for locale in supported_locales:
    i18n.set_locale(locale)
    culture = i18n.get_culture_settings(locale)
    
    print(f"\n--- {culture.display_name} ({culture.native_name}) ---")
    print(f"Text Direction: {culture.text_direction.value}")
    print(f"Currency: {culture.currency_code} ({culture.currency_symbol})")
    
    # Show translations
    for key in translation_examples[:3]:  # Show first 3 for brevity
        translation = i18n.translate(key, locale)
        print(f"  {key}: {translation}")

# Demonstrate formatting capabilities
print(f"\nüìÖ Locale-Specific Formatting Examples:")

current_time = time.time()
test_amount = 1234.56

for locale in [SupportedLocale.EN_US, SupportedLocale.DE_DE, SupportedLocale.JA_JP]:
    culture = i18n.get_culture_settings(locale)
    
    formatted_date = i18n.format_date(current_time, locale)
    formatted_currency = i18n.format_currency(test_amount, locale)
    
    print(f"{culture.display_name}:")
    print(f"  Date: {formatted_date}")
    print(f"  Currency: {formatted_currency}")

# Auto-detection demonstration
print(f"\nüéØ Auto-Detection Examples:")
test_headers = [
    {"Accept-Language": "de-DE,de;q=0.9,en;q=0.8"},
    {"Accept-Language": "fr-FR,fr;q=0.9,en;q=0.7"},
    {"Accept-Language": "ja,ja-JP;q=0.8,en;q=0.7"}
]

for headers in test_headers:
    detected = i18n.auto_detect_locale(headers)
    if detected:
        culture = i18n.get_culture_settings(detected)
        print(f"  {headers['Accept-Language']} ‚Üí {culture.display_name}")
```

### Compliance Management

```python
#!/usr/bin/env python3
"""
Global-First Tutorial: Compliance Management
"""

from privacy_finetuner.global_first import ComplianceManager, DataCategory, ProcessingPurpose
import time

# Initialize Compliance Manager
print("üåç Setting up Global Compliance Management...")

compliance_manager = ComplianceManager(
    primary_regions=["EU", "California", "Canada"],
    enable_real_time_monitoring=True,
    auto_remediation=True,
    privacy_officer_contact="privacy@tutorial.com"
)

# Start compliance monitoring
compliance_manager.start_compliance_monitoring()

# Register compliance violation callback
def compliance_alert_handler(violation):
    print(f"üö® Compliance Alert: {violation.framework.value}")
    print(f"   Region: {violation.region}")
    print(f"   Severity: {violation.severity}")
    print(f"   Description: {violation.description}")

compliance_manager.register_compliance_callback("tutorial_alerts", compliance_alert_handler)

print("‚úÖ Compliance monitoring started for EU, California, and Canada")

# Record data processing activities
print(f"\nüìù Recording Data Processing Activities...")

processing_activities = [
    {
        "name": "EU User Training Data",
        "categories": [DataCategory.PERSONAL_IDENTIFIERS, DataCategory.BEHAVIORAL_DATA],
        "purpose": ProcessingPurpose.MACHINE_LEARNING,
        "legal_basis": "legitimate_interests",
        "subjects": 25000,
        "location": "eu-west-1"
    },
    {
        "name": "California Consumer Data",
        "categories": [DataCategory.PERSONAL_IDENTIFIERS, DataCategory.DEVICE_DATA],
        "purpose": ProcessingPurpose.RESEARCH,
        "legal_basis": "consent",
        "subjects": 15000,
        "location": "us-west-1"
    },
    {
        "name": "Canadian Research Dataset",
        "categories": [DataCategory.BEHAVIORAL_DATA],
        "purpose": ProcessingPurpose.RESEARCH,
        "legal_basis": "consent",
        "subjects": 8000,
        "location": "canada-central-1"
    }
]

processing_ids = []
for activity in processing_activities:
    processing_id = compliance_manager.record_data_processing(
        data_categories=activity["categories"],
        processing_purpose=activity["purpose"],
        legal_basis=activity["legal_basis"],
        data_subjects_count=activity["subjects"],
        storage_location=activity["location"],
        retention_period=365
    )
    processing_ids.append(processing_id)
    print(f"‚úÖ Recorded: {activity['name']} (ID: {processing_id})")

# Record consent examples
print(f"\n‚úçÔ∏è Recording Data Subject Consents...")

consent_examples = [
    {"subject": "eu_user_001", "purposes": ["machine_learning", "analytics"]},
    {"subject": "ca_user_002", "purposes": ["research", "analytics"]},
    {"subject": "ca_user_003", "purposes": ["machine_learning"]},
]

consent_ids = []
for consent in consent_examples:
    consent_id = compliance_manager.record_consent(
        data_subject_id=consent["subject"],
        consent_purposes=consent["purposes"],
        consent_method="explicit",
        withdrawal_mechanism=True
    )
    consent_ids.append(consent_id)
    print(f"‚úÖ Consent recorded for {consent['subject']}: {', '.join(consent['purposes'])}")

# Demonstrate data subject rights handling
print(f"\nüë§ Handling Data Subject Rights Requests...")

rights_requests = [
    {"type": "access", "subject": "eu_user_001", "region": "EU"},
    {"type": "opt_out_sale", "subject": "ca_user_002", "region": "California"},
    {"type": "erasure", "subject": "eu_user_001", "region": "EU"}
]

for request in rights_requests:
    response = compliance_manager.handle_data_subject_request(
        request_type=request["type"],
        data_subject_id=request["subject"],
        region=request["region"]
    )
    
    print(f"üìã {request['type'].title()} request for {request['subject']}: {response['status']}")
    if response.get('estimated_completion'):
        print(f"   Estimated completion: {response['estimated_completion']}")

# Monitor for a short period
print(f"\nüëÄ Monitoring compliance for 10 seconds...")
time.sleep(10)

# Generate compliance report
print(f"\nüìä Generating Compliance Report...")
compliance_report = compliance_manager.generate_compliance_report()

print(f"Compliance Report Summary:")
print(f"  Active Violations: {compliance_report['compliance_overview']['active_violations']}")
print(f"  Processing Records: {compliance_report['compliance_overview']['processing_records']}")
print(f"  Consent Records: {compliance_report['compliance_overview']['consent_records']}")
print(f"  Frameworks Supported: {len(compliance_report['compliance_overview']['frameworks_supported'])}")

# Stop monitoring
compliance_manager.stop_compliance_monitoring()
```

---

## üéØ Real-World Use Cases

Let's put it all together with realistic scenarios.

### Healthcare AI with HIPAA Compliance

```python
#!/usr/bin/env python3
"""
Real-World Use Case: Healthcare AI with HIPAA Compliance
"""

from privacy_finetuner import PrivateTrainer, PrivacyConfig, ContextGuard, RedactionStrategy
from privacy_finetuner.global_first import ComplianceManager, DataCategory, ProcessingPurpose
from privacy_finetuner.security import ThreatDetector

print("üè• Healthcare AI Use Case: HIPAA-Compliant Medical Text Analysis")
print("=" * 70)

# Step 1: Setup HIPAA-Compliant Privacy Configuration
hipaa_privacy_config = PrivacyConfig(
    epsilon=0.5,  # Stricter privacy for healthcare
    delta=1e-7,   # Lower delta for medical data
    max_grad_norm=0.5,  # Conservative gradient clipping
    accounting_mode="gdp",  # Gaussian DP for tighter bounds
    secure_rng=True
)

# Step 2: Initialize Healthcare-Specific Context Protection
healthcare_context_guard = ContextGuard(
    strategies=[
        RedactionStrategy.PII_REMOVAL,
        RedactionStrategy.ENTITY_HASHING,
        RedactionStrategy.SEMANTIC_ENCRYPTION
    ],
    sensitivity_threshold=0.95,  # Very high sensitivity
    preserve_structure=True
)

# Step 3: Setup HIPAA Compliance Monitoring
hipaa_compliance = ComplianceManager(
    primary_regions=["US_Healthcare"],
    enable_real_time_monitoring=True,
    auto_remediation=True,
    privacy_officer_contact="hipaa-officer@hospital.com"
)

hipaa_compliance.start_compliance_monitoring()

# Step 4: Record HIPAA-Compliant Data Processing
processing_id = hipaa_compliance.record_data_processing(
    data_categories=[DataCategory.HEALTH_DATA, DataCategory.SENSITIVE_PERSONAL],
    processing_purpose=ProcessingPurpose.RESEARCH,
    legal_basis="consent",
    data_subjects_count=1000,
    storage_location="us-east-1-healthcare",
    retention_period=2555  # 7 years as required by HIPAA
)

print(f"‚úÖ HIPAA processing activity recorded: {processing_id}")

# Step 5: Protect Healthcare Data
healthcare_texts = [
    "Patient John Doe, DOB 01/15/1980, SSN 123-45-6789, diagnosed with diabetes mellitus type 2.",
    "Blood pressure reading for Mary Smith (MRN: 456789) was 140/90 mmHg on 03/15/2024.",
    "Prescription: Metformin 500mg twice daily for patient ID P12345, insurance policy #INS789123."
]

print(f"\nüõ°Ô∏è Applying Healthcare-Grade Privacy Protection:")
protected_texts = []
for i, text in enumerate(healthcare_texts, 1):
    result = healthcare_context_guard.protect(
        text, 
        sensitivity_level="high",
        preserve_entities=["medical_condition", "medication"]
    )
    protected_texts.append(result.protected_text)
    print(f"{i}. Original: {text}")
    print(f"   Protected: {result.protected_text}")
    print(f"   Sensitivity: {result.sensitivity_score:.2f}")

# Step 6: Initialize Healthcare AI Trainer
healthcare_trainer = PrivateTrainer(
    model_name="microsoft/DialoGPT-medium",
    privacy_config=hipaa_privacy_config,
    use_mcp_gateway=True,
    enable_context_guard=True
)

# Step 7: Setup Security Monitoring
healthcare_security = ThreatDetector(
    alert_threshold=0.9,  # Very sensitive for healthcare
    enable_automated_response=True
)

healthcare_security.start_monitoring()

print(f"\nüîí Healthcare AI system fully configured with:")
print(f"  ‚Ä¢ HIPAA-compliant privacy configuration (Œµ={hipaa_privacy_config.epsilon})")
print(f"  ‚Ä¢ Healthcare-grade context protection")
print(f"  ‚Ä¢ Real-time compliance monitoring")
print(f"  ‚Ä¢ Enhanced security threat detection")
print(f"  ‚Ä¢ 7-year data retention policy")

# Cleanup
healthcare_security.stop_monitoring()
hipaa_compliance.stop_compliance_monitoring()
```

### Financial Services with SOX Compliance

```python
#!/usr/bin/env python3
"""
Real-World Use Case: Financial Services with SOX Compliance
"""

from privacy_finetuner import PrivateTrainer, PrivacyConfig
from privacy_finetuner.global_first import ComplianceManager
from privacy_finetuner.scaling import AutoScaler, ScalingPolicy
import json

print("üè¶ Financial Services Use Case: SOX-Compliant Fraud Detection")
print("=" * 70)

# Financial-grade privacy configuration
finance_privacy_config = PrivacyConfig(
    epsilon=2.0,  # Balanced privacy for financial data
    delta=1e-6,
    max_grad_norm=1.2,
    accounting_mode="rdp",
    adaptive_clipping=True
)

# Setup multi-region compliance (US financial regulations)
finance_compliance = ComplianceManager(
    primary_regions=["US", "EU"],  # US SOX + EU GDPR
    enable_real_time_monitoring=True,
    auto_remediation=True
)

# Create financial training dataset
financial_data = [
    {
        "transaction": "Credit card payment $150.00 at grocery store",
        "risk_score": 0.1,
        "label": "legitimate"
    },
    {
        "transaction": "ATM withdrawal $500.00 at 3 AM in foreign country",
        "risk_score": 0.8,
        "label": "suspicious"
    },
    {
        "transaction": "Online purchase $2,500.00 electronics",
        "risk_score": 0.4,
        "label": "review"
    }
]

# Save financial dataset
with open('financial_training_data.jsonl', 'w') as f:
    for item in financial_data:
        f.write(json.dumps(item) + '\n')

# Initialize financial AI trainer
finance_trainer = PrivateTrainer(
    model_name="microsoft/DialoGPT-small",
    privacy_config=finance_privacy_config,
    use_mcp_gateway=True
)

# Setup auto-scaling for financial workloads
finance_scaling_policy = ScalingPolicy(
    policy_name="financial_services_scaling",
    min_nodes=3,  # Always maintain minimum for availability
    max_nodes=20,
    cost_constraints={"max_hourly_cost": 500.0},
    privacy_constraints={"min_nodes_for_privacy": 5}
)

finance_scaler = AutoScaler(
    scaling_policy=finance_scaling_policy,
    enable_cost_optimization=True
)

print(f"‚úÖ Financial Services AI Pipeline Configured:")
print(f"  ‚Ä¢ SOX/GDPR compliance monitoring active")
print(f"  ‚Ä¢ Privacy-preserving fraud detection model")
print(f"  ‚Ä¢ Auto-scaling for high availability (3-20 nodes)")
print(f"  ‚Ä¢ Cost-controlled scaling (max $500/hour)")
print(f"  ‚Ä¢ Privacy budget: Œµ={finance_privacy_config.epsilon}")

# Record compliance activity
processing_id = finance_compliance.record_data_processing(
    data_categories=["financial_data", "transaction_history"],
    processing_purpose="fraud_detection",
    legal_basis="legitimate_interests",
    data_subjects_count=100000,
    storage_location="us-east-1-finance",
    retention_period=2555  # 7 years for SOX compliance
)

print(f"‚úÖ SOX-compliant processing recorded: {processing_id}")

# Train fraud detection model
print(f"\nü§ñ Training Privacy-Preserving Fraud Detection Model...")
result = finance_trainer.train(
    dataset="financial_training_data.jsonl",
    epochs=1,  # Quick demo
    batch_size=2,
    output_dir="./finance_models"
)

print(f"‚úÖ Financial AI model training completed")
print(f"  Privacy spent: Œµ={result.privacy_spent.epsilon:.4f}")
print(f"  Model ready for fraud detection deployment")
```

---

## üöÄ Next Steps

Congratulations! You've completed the comprehensive quick start tutorial. Here's what you can explore next:

### üî¨ **Deep Dive Areas**

1. **Advanced Privacy Research**
   ```bash
   python examples/generation1_demo.py
   python examples/research_demo.py
   ```

2. **Enterprise Security Features**
   ```bash
   python examples/generation2_demo.py
   python examples/quality_gates_demo.py
   ```

3. **Production Scaling**
   ```bash
   python examples/generation3_demo.py
   python examples/advanced_scaling.py
   ```

4. **Global Deployment**
   ```bash
   python examples/global_first_demo.py
   ```

### üìö **Additional Resources**

- **[Production Deployment Guide](PRODUCTION_DEPLOYMENT_GUIDE.md)** - Deploy to Kubernetes, AWS, Azure, GCP
- **[API Reference](API_REFERENCE.md)** - Complete API documentation
- **[Architecture Deep Dive](ARCHITECTURE_DEEP_DIVE.md)** - Technical architecture details
- **[Implementation Status](IMPLEMENTATION_STATUS.md)** - Current feature matrix

### üõ†Ô∏è **Development Setup**

```bash
# Setup development environment
git clone https://github.com/your-org/privacy-preserving-agent-finetuner
cd privacy-preserving-agent-finetuner

# Install development dependencies
poetry install --with dev

# Run comprehensive tests
pytest tests/ -v

# Run all generation demos
make run-demos
```

### üåü **Key Features Explored**

‚úÖ **Basic Privacy-Preserving Training** with DP-SGD  
‚úÖ **Context Protection** for sensitive data  
‚úÖ **Real-Time Security Monitoring** with threat detection  
‚úÖ **Failure Recovery** with privacy preservation  
‚úÖ **Performance Optimization** with adaptive strategies  
‚úÖ **Auto-Scaling** with privacy constraints  
‚úÖ **Global Compliance** (GDPR, CCPA, HIPAA)  
‚úÖ **Multi-Language Support** with 20+ locales  
‚úÖ **Real-World Use Cases** in healthcare and finance  

### üéØ **Production Checklist**

Before deploying to production:

- [ ] Configure appropriate privacy budgets for your use case
- [ ] Setup monitoring and alerting systems
- [ ] Implement backup and recovery procedures
- [ ] Configure compliance frameworks for your region
- [ ] Setup auto-scaling policies
- [ ] Test security response procedures
- [ ] Validate privacy guarantees mathematically
- [ ] Setup multi-region deployment if needed
- [ ] Configure cost optimization policies
- [ ] Train your team on the privacy-preserving workflow

### üí¨ **Support & Community**

- **Documentation**: https://docs.your-org.com/privacy-finetuner
- **Issues**: https://github.com/your-org/privacy-preserving-agent-finetuner/issues  
- **Discussions**: https://github.com/your-org/privacy-preserving-agent-finetuner/discussions
- **Email Support**: privacy-ai@your-org.com

---

üéâ **Congratulations!** You now have hands-on experience with the world's most advanced privacy-preserving ML framework. Start building privacy-first AI applications that comply with global regulations while maintaining state-of-the-art performance!